{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5: Distributional semantics\n",
    "\n",
    "This is due on **11/27 (11:55pm)**, submitted electronically. \n",
    "\n",
    "## How to do this problem set\n",
    "\n",
    "Most of these questions require writing Python code and computing results, and the rest of them have textual answers.  Write all the textual answers in this document, show the output of your experiment in this document, and implement the functions in the `distsim.py`. Once you are finished, you will upload this `.ipynb` file and `distsim.py` to Moodle.\n",
    "\n",
    "* When creating your final version of the problem set to hand in, please do a fresh restart and execute every cell in order.  Then you'll be sure it's actually right.  Make sure to press \"Save\"!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Name:**\n",
    "\n",
    "**List collaborators, and how you collaborated, here:** (see our [grading and policies page](http://people.cs.umass.edu/~brenocon/inlp2016/grading.html) for details on our collaboration policy).\n",
    "\n",
    "* Rafael Lizarralde "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that, where $i$ indexes over the context types, cosine similarity is defined as follows. $x$ and $y$ are both vectors of context counts (each for a different word), where $x_i$ is the count of context $i$.\n",
    "\n",
    "$$cossim(x,y) = \\frac{ \\sum_i x_i y_i }{ \\sqrt{\\sum_i x_i^2} \\sqrt{\\sum_i y_i^2} }$$\n",
    "\n",
    "The nice thing about cosine similarity is that it is normalized: no matter what the input vectors are, the output is between 0 and 1. One way to think of this is that cosine similarity is just, um, the cosine function, which has this property (for non-negative $x$ and $y$). Another way to think of it is, to work through the situations of maximum and minimum similarity between two context vectors, starting from the definition above.\n",
    "\n",
    "Note: a good way to understand the cosine similarity function is that the numerator cares about whether the $x$ and $y$ vectors are correlated. If $x$ and $y$ tend to have high values for the same contexts, the numerator tends to be big. The denominator can be thought of as a normalization factor: if all the values of $x$ are really large, for example, dividing by the square root of their sum-of-squares prevents the whole thing from getting arbitrarily large. In fact, dividing by both these things (aka their norms) means the whole thing can’t go higher than 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 (10 points)\n",
    "\n",
    "See the file `nytcounts.university_cat_dog`, which contains context count vectors for three words: “dog”, “cat”, and “university”. These are immediate left and right contexts from a New York Times corpus. You can open the file in a text editor since it’s quite small.\n",
    "\n",
    "Please complete `cossim_sparse(v1,v2)` in `distsim.py` to compute and display the cosine similarities between each pair of these words. Briefly comment on whether the relative simlarities make sense.\n",
    "\n",
    "Note that we’ve provided very simple code that tests the context count vectors from the data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file nytcounts.university_cat_dog has contexts for 3 words\n",
      "Cosine similarity between cat and dog 0.966891672715\n",
      "Cosine similarity between cat and university 0.660442421144\n",
      "Cosine similarity between university and dog 0.659230248969\n"
     ]
    }
   ],
   "source": [
    "import distsim; reload(distsim)\n",
    "\n",
    "word_to_ccdict = distsim.load_contexts(\"nytcounts.university_cat_dog\")\n",
    "print \"Cosine similarity between cat and dog\" ,distsim.cossim_sparse(word_to_ccdict['cat'],word_to_ccdict['dog'])\n",
    "print \"Cosine similarity between cat and university\" ,distsim.cossim_sparse(word_to_ccdict['cat'],word_to_ccdict['university'])\n",
    "print \"Cosine similarity between university and dog\" ,distsim.cossim_sparse(word_to_ccdict['university'],word_to_ccdict['dog'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The relative similarities makes sense as the metric gives a significantly higher value to (cat,dog) pair as oposed to (cat, univeristy) or (dog, university).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 (15 points)\n",
    "\n",
    "Implement `show_nearest()`. \n",
    "Given a dictionary of word-context vectors, the context vector of a particular query word `w`, the words you want to exclude in the responses (It should be the query word `w` in this question), and the similarity metric you want to use (It should be the `cossim_sparse` function you just implemented), `show_nearest()` finds the 20 words most-similar to `w`. For each, display the other word, and its similarity to the query word `w`.\n",
    "\n",
    "To make sure it’s working, feel free to use the small `nytcounts.university_cat_dog` database as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file nytcounts.university_cat_dog has contexts for 3 words\n",
      "cat : 0.966891672715\n",
      "university : 0.659230248969\n"
     ]
    }
   ],
   "source": [
    "import distsim\n",
    "word_to_ccdict = distsim.load_contexts(\"nytcounts.university_cat_dog\")\n",
    "distsim.show_nearest(word_to_ccdict, word_to_ccdict['dog'], set(['dog']), distsim.cossim_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 (20 points)\n",
    "\n",
    "Explore similarities in `nytcounts.4k`, which contains context counts for about 4000 words in a sample of New York Times. The news data was lowercased and URLs were removed. The context counts are for the 2000 most common words in twitter, as well as the most common 2000 words in the New York Times. (But all context counts are from New York Times.) The context counts only contain contexts that appeared for more than one word. The file `vocab` contains the list of all terms in this data, along with their total frequency.\n",
    "Choose **six** words. For each, show the output of `show_nearest()` and comment on whether the output makes sense. Comment on whether this approach to distributional similarity makes more or less sense for certain terms.\n",
    "Four of your words should be:\n",
    "\n",
    " * a name (for example: person, organization, or location)\n",
    " * a common noun\n",
    " * an adjective\n",
    " * a verb\n",
    "\n",
    "You may also want to try exploring further words that are returned from a most-similar list from one of these. You can think of this as traversing the similarity graph among words.\n",
    "\n",
    "*Implementation note:* \n",
    "On my laptop it takes several hundred MB of memory to load it into memory from the `load_contexts()` function. If you don’t have enough memory available, your computer will get very slow because the OS will start swapping. If you have to use a machine without that much memory available, you can instead implement in a streaming approach by using the `stream_contexts()` generator function to access the data; this lets you iterate through the data from disk, one vector at a time, without putting everything into memory. You can see its use in the loading function. (You could also alternatively use a key-value or other type of database, but that’s too much work for this assignment.)\n",
    "\n",
    "*Extra note:* \n",
    "You don’t need this, but for reference, our preprocessing scripts we used to create the context data are in the `preproc/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file nytcounts.4k has contexts for 3648 words\n"
     ]
    }
   ],
   "source": [
    "import distsim; reload(distsim)\n",
    "word_to_ccdict = distsim.load_contexts(\"nytcounts.4k\")\n",
    "###Provide your answer below; perhaps in another cell so you don't have to reload the data each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paris : 0.969922701547\n",
      "washington : 0.966413121743\n",
      "baghdad : 0.960228810316\n",
      "iraq : 0.956542488425\n",
      "atlanta : 0.954037925324\n",
      "2000 : 0.948294403121\n",
      "chicago : 0.947112215726\n",
      "philadelphia : 0.947008542809\n",
      "europe : 0.945073821088\n",
      "manhattan : 0.943055053744\n",
      "2002 : 0.942927981567\n",
      "1998 : 0.942282912202\n",
      "2003 : 0.939722684448\n",
      "1996 : 0.939628513887\n",
      "1999 : 0.934767034178\n",
      "1994 : 0.931474672799\n",
      "miami : 0.930494514481\n",
      "1997 : 0.927593121476\n",
      "1995 : 0.926635164544\n",
      "jail : 0.926115332412\n",
      "florida : 0.922942736016\n"
     ]
    }
   ],
   "source": [
    "###Answer examples\n",
    "distsim.show_nearest(word_to_ccdict, word_to_ccdict['london'],set(['london']),distsim.cossim_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the output makes sense as it lists the tokens mostly countries, cities and years thats relevant to London in terms of news as the counts of context are from New York times and twitter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "david : 0.934898603227\n",
      "peter : 0.929509857942\n",
      "jonathan : 0.923215513894\n",
      "andrew : 0.922229193309\n",
      "robert : 0.913586443217\n",
      "susan : 0.913104358468\n",
      "chris : 0.912410311969\n",
      "daniel : 0.910650063728\n",
      "james : 0.90213572096\n",
      "steven : 0.901382235893\n",
      "adam : 0.898352454499\n",
      "jim : 0.891580206908\n",
      "jennifer : 0.887926912004\n",
      "richard : 0.881836031176\n",
      "steve : 0.879818282158\n",
      "william : 0.8755367179\n",
      "nancy : 0.875534147136\n",
      "kevin : 0.874963882108\n",
      "anthony : 0.86890606037\n",
      "justin : 0.865493576771\n",
      "matt : 0.865227025353\n"
     ]
    }
   ],
   "source": [
    "distsim.show_nearest(word_to_ccdict, word_to_ccdict['eric'],set(['eric']),distsim.cossim_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributional similarity has resulted in other proper nouns mainly names of people due to the common context shared by them. This is as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neighbors : 0.781064727475\n",
      "doctors : 0.776508758064\n",
      "clothes : 0.753363197835\n",
      "books : 0.749142873592\n",
      "writers : 0.745011556811\n",
      "developers : 0.743908047393\n",
      "musicians : 0.740890960915\n",
      "teachers : 0.740734917438\n",
      "proposals : 0.734189373102\n",
      "democrats : 0.732364286141\n",
      "ideas : 0.731754421717\n",
      "parents : 0.730339486114\n",
      "drivers : 0.729310356034\n",
      "republicans : 0.728771597727\n",
      "clothing : 0.727037686977\n",
      "players : 0.726445096246\n",
      "horses : 0.724292847834\n",
      "students : 0.723455822114\n",
      "talent : 0.722829138602\n",
      "witnesses : 0.720642712864\n",
      "fans : 0.719940600682\n"
     ]
    }
   ],
   "source": [
    "distsim.show_nearest(word_to_ccdict, word_to_ccdict['lawyers'],set(['lawyers']),distsim.cossim_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all the terms in the list are common nouns though most of them are not  quite relevant to lawyers as one would expect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "significant : 0.896394608995\n",
      "successful : 0.874107623898\n",
      "good : 0.87261355999\n",
      "strong : 0.871730541815\n",
      "powerful : 0.865286620101\n",
      "rare : 0.862773035956\n",
      "small : 0.860530784884\n",
      "large : 0.858372185891\n",
      "terrible : 0.856937087099\n",
      "wonderful : 0.853802055021\n",
      "beautiful : 0.8481101697\n",
      "lovely : 0.84390752851\n",
      "strange : 0.843154034069\n",
      "sharp : 0.842517415649\n",
      "healthy : 0.842224450257\n",
      "specific : 0.84009620961\n",
      "special : 0.838683100859\n",
      "huge : 0.837980367336\n",
      "different : 0.836788475073\n",
      "simple : 0.836450307935\n",
      "brief : 0.835471025749\n"
     ]
    }
   ],
   "source": [
    "distsim.show_nearest(word_to_ccdict, word_to_ccdict['serious'],set(['serious']),distsim.cossim_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again as the query word, the result is mostly adjectives but not all relevant to serious. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "region : 0.937184233374\n",
      "state : 0.933963707974\n",
      "country : 0.921173376926\n",
      "company : 0.921073569216\n",
      "governor : 0.913328882314\n",
      "world : 0.90418263635\n",
      "sun : 0.903656128098\n",
      "bride : 0.898366691474\n",
      "government : 0.896816725136\n",
      "band : 0.893184292775\n",
      "pentagon : 0.889174003997\n",
      "planet : 0.886205908968\n",
      "nation : 0.884027868613\n",
      "agency : 0.88362360939\n",
      "film : 0.881995169291\n",
      "legislature : 0.881328609258\n",
      "bronx : 0.876154206439\n",
      "heat : 0.872157801128\n",
      "ball : 0.871896409723\n",
      "panel : 0.871348598272\n",
      "sport : 0.871164815239\n"
     ]
    }
   ],
   "source": [
    "distsim.show_nearest(word_to_ccdict, word_to_ccdict['city'],set(['city']),distsim.cossim_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buy : 0.966328233154\n",
      "get : 0.964068235843\n",
      "make : 0.961741234641\n",
      "send : 0.959847755132\n",
      "take : 0.959722625802\n",
      "produce : 0.959285007969\n",
      "develop : 0.958554140172\n",
      "build : 0.95656186285\n",
      "provide : 0.954616275432\n",
      "write : 0.951020358045\n",
      "see : 0.948156108201\n",
      "hold : 0.9478776166\n",
      "maintain : 0.947026040175\n",
      "create : 0.943193650106\n",
      "bring : 0.938538746987\n",
      "earn : 0.937658288596\n",
      "fill : 0.936945845902\n",
      "carry : 0.935415124589\n",
      "wear : 0.934061056165\n",
      "prevent : 0.933595815203\n",
      "kill : 0.933212055104\n"
     ]
    }
   ],
   "source": [
    "distsim.show_nearest(word_to_ccdict, word_to_ccdict['find'],set(['find']),distsim.cossim_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results mostly verb. Word too generic to define expectation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As noted in the output of most query word, distributional similarity tends to capture the word type accurately due to the shared context words. Based on how you qualitatively define similarity this emphasis on word type may or may not be what you expect. Personally, I would like to explore similarity in a broader sense based on the word meaning. Distributional similarity would then not match my expectation well. Also, it has a poor geberalizability.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 (10 points)\n",
    "\n",
    "In the next several questions, you'll examine similarities in trained word embeddings, instead of raw context counts.\n",
    "\n",
    "See the file `nyt_word2vec.university_cat_dog`, which contains word embedding vectors pretrained by word2vec [1] for three words: “dog”, “cat”, and “university”. You can open the file in a text editor since it’s quite small.\n",
    "\n",
    "Please complete `cossim_dense(v1,v2)` in `distsim.py` to compute and display the cosine similarities between each pair of these words.\n",
    "\n",
    "*Implementation note:*\n",
    "Notice that the inputs of `cossim_dense(v1,v2)` are numpy arrays. If you do not very familiar with the basic operation in numpy, you can find some examples in the basic operation section here:\n",
    "https://docs.scipy.org/doc/numpy-dev/user/quickstart.html\n",
    "\n",
    "If you know how to use Matlab but haven't tried numpy before, the following link should be helpful:\n",
    "https://docs.scipy.org/doc/numpy-dev/user/numpy-for-matlab-users.html\n",
    "\n",
    "[1] Mikolov, Tomas, et al. \"Distributed representations of words and phrases and their compositionality.\" NIPS 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity between cat and dog 0.827517295965\n",
      "Cosine similarity between cat and university -0.205394745036\n",
      "Cosine similarity between university and dog -0.190753135501\n",
      "cat : 0.827517295965\n",
      "university : -0.190753135501\n"
     ]
    }
   ],
   "source": [
    "import distsim; reload(distsim)\n",
    "word_to_vec_dict = distsim.load_word2vec(\"nyt_word2vec.university_cat_dog\")\n",
    "print \"Cosine similarity between cat and dog\" ,distsim.cossim_dense(word_to_vec_dict['cat'],word_to_vec_dict['dog'])\n",
    "print \"Cosine similarity between cat and university\" ,distsim.cossim_dense(word_to_vec_dict['cat'],word_to_vec_dict['university'])\n",
    "print \"Cosine similarity between university and dog\" ,distsim.cossim_dense(word_to_vec_dict['university'],word_to_vec_dict['dog'])\n",
    "\n",
    "word_to_vec_dict = distsim.load_word2vec(\"nyt_word2vec.university_cat_dog\")\n",
    "distsim.show_nearest(word_to_vec_dict, word_to_vec_dict['dog'], set(['dog']),distsim.cossim_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 (25 points)\n",
    "\n",
    "Repeat the process you did in the question 3, but now use dense vector from word2vec. Comment on whether the outputs makes sense. Compare the outputs of using `show_nearest()` on word2vec and the outputs on sparse context vector (so we suggest you to use the same words in question 3). Which method works better on the query words you choose. Please brief explain why one method works better than other in each case.\n",
    "\n",
    "Notice that we use default parameters of word2vec in [gensim](https://radimrehurek.com/gensim/models/word2vec.html) to get word2vec word embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import distsim\n",
    "word_to_vec_dict = distsim.load_word2vec(\"nyt_word2vec.4k\")\n",
    "###Provide your answer bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paris : 0.742107827129\n",
      "chicago : 0.676770811474\n",
      "philadelphia : 0.59429769204\n",
      "england : 0.587948398039\n",
      "newark : 0.578417918674\n",
      "boston : 0.571829045744\n",
      "madrid : 0.563767976184\n",
      "seattle : 0.55322589154\n",
      "spain : 0.544267480338\n",
      "australia : 0.540475332018\n",
      "york : 0.53997553081\n",
      "manhattan : 0.535027539424\n",
      "chelsea : 0.525994762298\n",
      "atlanta : 0.525622409271\n",
      "el : 0.524066431248\n",
      "washington : 0.514216746133\n",
      "1997 : 0.50900778333\n",
      "houston : 0.508965859676\n",
      "fashion : 0.503772688122\n",
      "1999 : 0.503085817215\n",
      "1996 : 0.50188590366\n"
     ]
    }
   ],
   "source": [
    "distsim.show_nearest(word_to_vec_dict, word_to_vec_dict['london'],set(['london']),distsim.cossim_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "significantly less years than places as compared to sparse logic. This output makes more sense to me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "brian : 0.894186570284\n",
      "daniel : 0.886016873831\n",
      "kevin : 0.875281443728\n",
      "gary : 0.869643812807\n",
      "jeff : 0.868130392477\n",
      "jonathan : 0.865974899608\n",
      "adam : 0.865754187497\n",
      "chris : 0.863424805911\n",
      "scott : 0.857978086682\n",
      "jim : 0.85097179025\n",
      "andrew : 0.850539452137\n",
      "bruce : 0.841079454436\n",
      "justin : 0.840832595618\n",
      "steve : 0.840444411046\n",
      "anthony : 0.838173516411\n",
      "tim : 0.834469543451\n",
      "larry : 0.833590575026\n",
      "david : 0.833193625701\n",
      "matt : 0.832877268667\n",
      "patrick : 0.831428141526\n",
      "jennifer : 0.829940531379\n"
     ]
    }
   ],
   "source": [
    "distsim.show_nearest(word_to_vec_dict, word_to_vec_dict['eric'],set(['eric']),distsim.cossim_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fewer girl names as compared to sparse logic. If I am interested in a particular domain, say the movie Titanic, I would not prefer this result as it is too generic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prosecutors : 0.775297156601\n",
      "investigators : 0.678165745168\n",
      "judges : 0.663011352717\n",
      "witnesses : 0.646656372143\n",
      "lawyer : 0.629047434705\n",
      "agents : 0.615615261957\n",
      "employees : 0.608172244932\n",
      "aides : 0.604734421243\n",
      "officers : 0.598752840552\n",
      "officials : 0.598640344387\n",
      "doctors : 0.596266981157\n",
      "actions : 0.591824133768\n",
      "papers : 0.591820696789\n",
      "clients : 0.589970894172\n",
      "testimony : 0.587679618257\n",
      "lawmakers : 0.581707235336\n",
      "opponents : 0.580216463071\n",
      "criminal : 0.573577738669\n",
      "authorities : 0.572877082566\n",
      "colleagues : 0.571763378261\n",
      "supporters : 0.571481622549\n"
     ]
    }
   ],
   "source": [
    "distsim.show_nearest(word_to_vec_dict, word_to_vec_dict['lawyers'],set(['lawyers']),distsim.cossim_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better representation of similarity as compared to sparse. More emphasis on word meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive : 0.699890292893\n",
      "significant : 0.68606746792\n",
      "critical : 0.658510985884\n",
      "negative : 0.609582955657\n",
      "crucial : 0.601757842358\n",
      "specific : 0.594108835655\n",
      "potential : 0.586777590992\n",
      "dangerous : 0.571456581401\n",
      "such : 0.561674828979\n",
      "common : 0.561278142439\n",
      "long-term : 0.557334708765\n",
      "physical : 0.546333122761\n",
      "certain : 0.545411746723\n",
      "terrible : 0.541384495838\n",
      "sexual : 0.536974606489\n",
      "particular : 0.535600508496\n",
      "risks : 0.533087121555\n",
      "accurate : 0.5295905936\n",
      "mental : 0.528871096944\n",
      "important : 0.523539731647\n",
      "difficult : 0.520717070132\n"
     ]
    }
   ],
   "source": [
    "distsim.show_nearest(word_to_vec_dict, word_to_vec_dict['serious'],set(['serious']),distsim.cossim_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "has a more negative connotation in the output as compared to the sparse output and goes well with the query word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "town : 0.727960723145\n",
      "state : 0.646071801271\n",
      "nation : 0.620838949994\n",
      "area : 0.618970739821\n",
      "region : 0.600232409368\n",
      "country : 0.593311950317\n",
      "neighborhood : 0.576728956949\n",
      "parks : 0.557922559453\n",
      "district : 0.553389193187\n",
      "county : 0.539186049261\n",
      "community : 0.528192322121\n",
      "newark : 0.519678589125\n",
      "downtown : 0.51847462255\n",
      "housing : 0.513368482927\n",
      "connecticut : 0.506858190453\n",
      "building : 0.49473467596\n",
      "westchester : 0.493845284477\n",
      "mayor : 0.48483016808\n",
      "communities : 0.4810677938\n",
      "residents : 0.473806226518\n",
      "authority : 0.472970790837\n"
     ]
    }
   ],
   "source": [
    "distsim.show_nearest(word_to_vec_dict, word_to_vec_dict['city'],set(['city']),distsim.cossim_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similar to sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get : 0.721049380383\n",
      "imagine : 0.718554980425\n",
      "see : 0.712686678472\n",
      "bring : 0.705328513736\n",
      "enjoy : 0.695330500537\n",
      "prove : 0.692737795753\n",
      "create : 0.687239780648\n",
      "ignore : 0.686548066275\n",
      "carry : 0.684808359136\n",
      "appreciate : 0.680417827671\n",
      "consider : 0.669722646314\n",
      "reach : 0.664784903209\n",
      "fill : 0.658821036432\n",
      "understand : 0.649937019684\n",
      "draw : 0.647413203766\n",
      "handle : 0.646085541075\n",
      "hide : 0.640297032571\n",
      "provide : 0.639882642894\n",
      "keep : 0.634017689362\n",
      "seek : 0.633712626869\n",
      "make : 0.633535005841\n"
     ]
    }
   ],
   "source": [
    "distsim.show_nearest(word_to_vec_dict, word_to_vec_dict['find'],set(['find']),distsim.cossim_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results mostly verb and similar to sparse. Word too generic to define expectation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The dense representation with word2vec in general seems to capture the word similairties better than the sparse representation. One disadvantage with this approach is that it ignores the domain or context and might need some finetuning to perform better. DisadvantageS with the sparse approach is the increase space and computation time, though the impact of this could be reduced with efficient algorithms. But this apparoach still dependends on quality of training data and poorer generalizability.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7 (15 points)\n",
    "After you have word embedding, one of interesting things you can do is to perform analogical reasoning tasks. In the following example, we provide the code which can find the closet words to the vector $v_{king}-v_{man}+v_{woman}$ to fill the blank on the question:\n",
    "\n",
    "king : man = ____ : woman\n",
    "\n",
    "Notice that the word2vec is trained in an unsupervised manner; it is impressive that it can apparently do an interesting type of reasoning.  (For a contrary opinion, see [Linzen 2016](http://www.aclweb.org/anthology/W/W16/W16-2503.pdf).)\n",
    "\n",
    "Please come up with another analogical reasoning task (another triple of words), and output the answer using the the same method. Comment on whether the output makes sense. If the output makes sense, explain why we can capture such relation between words using an unsupervised algorithm. Where does the information come from? On the other hand, if the output does not make sense, propose an explanation why the algorithm fails on this case.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queen : 0.725028631986\n",
      "princess : 0.577900103401\n",
      "prince : 0.566962392417\n",
      "lord : 0.530919391111\n",
      "royal : 0.520203296864\n",
      "mary : 0.497698146284\n",
      "mama : 0.495469636832\n",
      "daughter : 0.493757946566\n",
      "singer : 0.489838082014\n",
      "kim : 0.488354695243\n",
      "elizabeth : 0.482484843405\n",
      "girl : 0.477338294808\n",
      "grandma : 0.476990726681\n",
      "sister : 0.470304371825\n",
      "mother : 0.469422028833\n",
      "clark : 0.46824004741\n",
      "wedding : 0.46233629356\n",
      "husband : 0.456851188179\n",
      "boyfriend : 0.447550574504\n",
      "jesus : 0.438572115806\n",
      "wolf : 0.428880090916\n"
     ]
    }
   ],
   "source": [
    "import distsim\n",
    "king = word_to_vec_dict['king']\n",
    "man = word_to_vec_dict['man']\n",
    "woman = word_to_vec_dict['woman']\n",
    "distsim.show_nearest(word_to_vec_dict,\n",
    "                     king-man+woman,\n",
    "                     set(['king','man','woman']),\n",
    "                     distsim.cossim_dense)\n",
    "###Provide your answer bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pink : 0.665804014903\n",
      "leather : 0.612621614795\n",
      "yellow : 0.611314615177\n",
      "red : 0.61031100343\n",
      "jeans : 0.602957248795\n",
      "black : 0.553939521626\n",
      "shorts : 0.553855150597\n",
      "shirt : 0.550835184438\n",
      "gray : 0.5483526129\n",
      "dress : 0.5470958903\n",
      "shirts : 0.543401892557\n",
      "bar : 0.542705288537\n",
      "tea : 0.53655740934\n",
      "pants : 0.52330855032\n",
      "tiny : 0.517971218307\n",
      "boots : 0.510116822657\n",
      "orange : 0.506494216352\n",
      "wings : 0.503183061064\n",
      "gold : 0.501217061816\n",
      "bright : 0.499989254229\n",
      "hat : 0.499151557984\n"
     ]
    }
   ],
   "source": [
    "import distsim\n",
    "blue = word_to_vec_dict['blue']\n",
    "man = word_to_vec_dict['man']\n",
    "woman = word_to_vec_dict['woman']\n",
    "distsim.show_nearest(word_to_vec_dict,\n",
    "                     blue-man+woman,\n",
    "                     set(['blue','man','woman']),\n",
    "                     distsim.cossim_dense)\n",
    "###Provide your answer bellow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write your response here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the output might hold true statistically, this seems like inducing stereotypes in our AI models. It would be wrong to assume the representation of our training data when the query in question is not factual. <br>\n",
    "earn-man = <>-man <br>\n",
    "receive : 0.671115468114 (best result)<br>\n",
    "earn-woman = <>-man <br>\n",
    "lose : 0.601115468114 (best result)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra credit (up to 5 points)\n",
    "\n",
    "Analyze word similarities with WordNet, and compare and contrast against the distributional similarity results. For a fair comparison, limit yourself to words in the `nytcounts.4k` vocabulary. First, calculate how many of the words are present in WordNet, at least based on what method you’re doing lookups with. (There is an issue that WordNet requires a part-of-speech for lookup, but we don’t have those in our data; you’ll have to devise a solution). \n",
    "\n",
    "Second, for the words you analyzed with distributional similarity above, now do the same with WordNet-based similarity as implemented in NLTK, as described <a href=\"http://www.nltk.org/howto/wordnet.html\">here</a>, or search for “nltk wordnet similarity”. For a fair comparison, do the nearest-similarity ranking among the words in the `nytcounts.4k` vocabulary. You may use `path_similarity`, or any of the other similarity methods (e.g. `res_similarity` for Resnik similarity, which is one of the better ones). Describe what you are doing. Compare and contrast the words you get. Does WordNet give similar or very different results? Why?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra credit (up to 5 points)\n",
    "\n",
    "Investigate a few of the alternative methods described in [Linzen 2016](http://www.aclweb.org/anthology/W/W16/W16-2503.pdf) on the man/woman/king/queen and your new example.  What does this tell you about the legitimacy of analogical reasoning tasks?  How do you assess Linzen's arguments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "girl : 0.792813108092\n",
      "boy : 0.790081430397\n",
      "queen : 0.681013287404\n",
      "princess : 0.641849033577\n",
      "prince : 0.622121026431\n",
      "girlfriend : 0.613567895305\n",
      "child : 0.612858977402\n",
      "cat : 0.612271393217\n",
      "soldier : 0.600440739677\n",
      "dog : 0.584798842347\n",
      "lord : 0.580856424775\n",
      "blonde : 0.580381252379\n",
      "singer : 0.577198587828\n",
      "mother : 0.57236750517\n",
      "kid : 0.565451894067\n",
      "doctor : 0.564419288952\n",
      "boyfriend : 0.554783097888\n",
      "cousin : 0.553546769661\n",
      "son : 0.547906679666\n",
      "person : 0.546853109787\n",
      "daughter : 0.546254916769\n"
     ]
    }
   ],
   "source": [
    "#IGNORE-A - Gender\n",
    "import distsim\n",
    "king = word_to_vec_dict['king']\n",
    "man = word_to_vec_dict['man']\n",
    "woman = word_to_vec_dict['woman']\n",
    "distsim.show_nearest(word_to_vec_dict,\n",
    "                     king+woman,\n",
    "                     set(['king','man','woman']),\n",
    "                     distsim.cossim_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afghanistan : 0.762437706802\n",
      "baghdad : 0.682714040439\n",
      "europe : 0.669691210578\n",
      "germany : 0.668746773533\n",
      "britain : 0.660849776008\n",
      "russia : 0.648489995123\n",
      "vietnam : 0.640047093237\n",
      "iran : 0.628611152017\n",
      "china : 0.62222874257\n",
      "france : 0.614384360429\n",
      "iraqi : 0.61407321472\n",
      "japan : 0.611422551556\n",
      "gaza : 0.611051792062\n",
      "military : 0.595761963932\n",
      "israel : 0.586398079713\n",
      "india : 0.563168459511\n",
      "region : 0.550751918723\n",
      "ukraine : 0.545003325069\n",
      "america : 0.540400151195\n",
      "italy : 0.538410391165\n",
      "pentagon : 0.533084366599\n"
     ]
    }
   ],
   "source": [
    "#IGNORE-A - Capital\n",
    "import distsim\n",
    "london = word_to_vec_dict['london']\n",
    "england = word_to_vec_dict['england']\n",
    "iraq = word_to_vec_dict['iraq']\n",
    "distsim.show_nearest(word_to_vec_dict,\n",
    "                     london+iraq,\n",
    "                     set(['london','england','iraq']),\n",
    "                     distsim.cossim_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "not as good as  ADD, mostly picks a neighbour of baghdad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "girl : 0.86383601422\n",
      "boy : 0.786581684421\n",
      "child : 0.678692596742\n",
      "person : 0.678675262709\n",
      "doctor : 0.643260732956\n",
      "soldier : 0.64201026603\n",
      "herself : 0.612077346824\n",
      "mother : 0.575203768415\n",
      "patient : 0.574240780618\n",
      "someone : 0.56777877143\n",
      "dog : 0.559724830678\n",
      "cat : 0.558030561205\n",
      "guy : 0.556801357775\n",
      "baby : 0.556227160654\n",
      "men : 0.555089484198\n",
      "kid : 0.553023348019\n",
      "boyfriend : 0.541439868409\n",
      "girlfriend : 0.540814530321\n",
      "daughter : 0.537658999991\n",
      "blonde : 0.536857529045\n",
      "she : 0.524530234881\n"
     ]
    }
   ],
   "source": [
    "#ONLY-B\n",
    "import distsim\n",
    "king = word_to_vec_dict['king']\n",
    "man = word_to_vec_dict['man']\n",
    "woman = word_to_vec_dict['woman']\n",
    "distsim.show_nearest(word_to_vec_dict,\n",
    "                     woman,\n",
    "                     set(['king','man','woman']),\n",
    "                     distsim.cossim_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noted by Linzen, this approach has a limitation and doesnt seem to work in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "girl : 0.777172950568\n",
      "boy : 0.72237968541\n",
      "person : 0.721604772155\n",
      "soldier : 0.643904819677\n",
      "guy : 0.609361570981\n",
      "doctor : 0.605059792372\n",
      "someone : 0.599356573486\n",
      "child : 0.595538385446\n",
      "patient : 0.595495936886\n",
      "kid : 0.529667791095\n",
      "men : 0.527004685204\n",
      "herself : 0.519762400929\n",
      "baby : 0.510893089607\n",
      "people : 0.498358675263\n",
      "dog : 0.498163543648\n",
      "teenagers : 0.495894233496\n",
      "smile : 0.488049182473\n",
      "naked : 0.4813396728\n",
      "artist : 0.466727763772\n",
      "cat : 0.466153077219\n",
      "girls : 0.462756807988\n"
     ]
    }
   ],
   "source": [
    "#ADD-OPPOSITE\n",
    "import distsim\n",
    "king = word_to_vec_dict['king']\n",
    "man = word_to_vec_dict['man']\n",
    "woman = word_to_vec_dict['woman']\n",
    "distsim.show_nearest(word_to_vec_dict,\n",
    "                     -(king-man)+woman,\n",
    "                     set(['king','man','woman']),\n",
    "                     distsim.cossim_dense)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mostly picks a neighbour of queen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "racing 46.2687226871\n"
     ]
    }
   ],
   "source": [
    "#MULTIPLY - GENDER\n",
    "import distsim\n",
    "from __future__ import division\n",
    "king = word_to_vec_dict['king']\n",
    "man = word_to_vec_dict['man']\n",
    "woman = word_to_vec_dict['woman']\n",
    "x_best = None\n",
    "x_best_val = -1\n",
    "for x in word_to_vec_dict:\n",
    "    if x !='king' and x !='man' and x !='woman':\n",
    "        x_king = distsim.cossim_dense(word_to_vec_dict[x],king)\n",
    "        x_woman = distsim.cossim_dense(word_to_vec_dict[x],woman)\n",
    "        x_man = distsim.cossim_dense(word_to_vec_dict[x],man)\n",
    "        x_this = (x_king*x_woman)/x_man\n",
    "        #print x_king,x_woman,x_man\n",
    "        #print x, x_this\n",
    "        if x_this > x_best_val:\n",
    "            x_best = x\n",
    "            x_best_val = x_this\n",
    "print x_best, x_best_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "racing seems to have a very low absolute value causing the objective function value to be very high. Not as expected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suppose 136.644600796\n"
     ]
    }
   ],
   "source": [
    "#MULTIPLY - CAPITALS\n",
    "#England:London = Iraq:Baghdad\n",
    "import distsim\n",
    "london = word_to_vec_dict['london']\n",
    "england = word_to_vec_dict['england']\n",
    "iraq = word_to_vec_dict['iraq']\n",
    "x_best = None\n",
    "x_best_val = -1\n",
    "for x in word_to_vec_dict:\n",
    "    if x !='london' and x !='england' and x !='iraq':\n",
    "        x_london = distsim.cossim_dense(word_to_vec_dict[x],london)\n",
    "        x_england = distsim.cossim_dense(word_to_vec_dict[x],england)\n",
    "        x_iraq = distsim.cossim_dense(word_to_vec_dict[x],iraq)\n",
    "        x_this = x_london*x_iraq/x_england\n",
    "        #print x_king,x_woman,x_man\n",
    "        #print x, x_this\n",
    "        if x_this > x_best_val:\n",
    "            x_best = x\n",
    "            x_best_val = x_this\n",
    "print x_best, x_best_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linzen's claims hold good for IGNORE-A, ONLY-B and ADD-OPPOSITE but doesnt work for MULTIPLY for the examples above."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
