{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2: N-gram Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is due on **Friday, Sept 23 (11:59pm)**, submitted electronically.\n",
    "\n",
    "You will submit two files: (1) this jupyter notebook file with answers, and also (2) hw2.py.  (do not include any other files.)\n",
    "\n",
    "We provide a starter version of hw2.py with stub functions that need to be completed.  Much of the code in this notebook calls functions from the hw2.py module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Your Name:** *Shamya Karumbaiah*\n",
    "\n",
    "* **List collaborators:** *Rafael Lizarralde*\n",
    "\n",
    "(see our [grading and policies page](http://people.cs.umass.edu/~brenocon/inlp2016/grading.html) for details on our collaboration policy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part A: Toy Example for Testing\n",
    "\n",
    "When implementing algorithms, it's crucial to design test cases to make sure your code works.  The best way to start is to run it on inputs where you know the correct answer in advance, or the range of correct answers.  (If you automate these types of tests, they're called _unit tests_ and are a standard technique in software engineering.)\n",
    "\n",
    "We'll take the approach of having a tiny, synthetic \"toy\" dataset to experiment with.  It's important to run tests on this first before real-world data.  Toy datasets run more quickly.  Also, outputs from real-world data might look good enough so that you miss bugs.\n",
    "\n",
    "Our toy example has a vocabulary of three word types \"A\", \"B\", and special \\*\\*START\\*\\* and \\*\\*END\\*\\* symbols.  We'll calculate some quantities by hand to help verify the correctness of your implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a toy corpus that's eight tokens long (including start/end tokens).\n",
    "```\n",
    "  **START** A A A B B B **END**\n",
    "```\n",
    "\n",
    "And here are the bigram counts.\n",
    "\n",
    "|        | wnext = A | wnext = B  |  wnext = \\*\\*END\\*\\*  | \n",
    "|--------|---------------|---|---|\n",
    "| wprev = A |         2          |  1 |  0 |\n",
    "| wprev = B |         0          | 2  |  1 |\n",
    "| wprev = \\*\\*START\\*\\* |     1          | 0  |  0 | \n",
    "\n",
    "\n",
    "And below is the same thing in Python dictionaries.  Evaluate the cell below, since we'll use this data later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "uni_counts_toy={\"A\":3,\"B\":3,\"**START**\":1,\"**END**\":1}\n",
    "bi_counts_toy={\"A\":{ \"A\": 2, \"B\":1 },\"B\": {\"B\":2,\"**END**\":1},\"**START**\":{\"A\":1} }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part B: Conditional Probability\n",
    "\n",
    "For a $k$-gram model (of history size $k-1$), and vocabulary size $V$, we have:\n",
    "\n",
    "$$ P(w_i | w_{i-k+1}..w_{i-1} ) = \\frac{ c(w_{i-k+1}..w_i) + \\alpha }{ c(w_{i-k+1}..w_{i-1}) + \\alpha V }. $$\n",
    "\n",
    "Where $\\alpha$ is the number of pseudocounts for every word type.  In lecture, we usually used $\\alpha=1$. In this homework we'll just use $k=1$ and $\\alpha=0$.\n",
    "\n",
    "We assume always that $w_1=$\\*\\*START\\*\\*, a special symbol denoting the start of a sentence.  A sentence always ends with the special symbol \\*\\*END\\*\\*.  In terms of the generative assumption of the model, the model assume a \\*\\*START\\*\\* symbol exists in the first position, then it generates words one by one.  When it generates a \\*\\*END\\*\\* symbol, the generative process stops.\n",
    "\n",
    "**Question B-1 (10 points):**\n",
    "\n",
    "Please compute the entire conditional probability table for $P(w_{next} | w_{prev1})$ for $w_{prev} \\in \\{A,B,\\text{**}START\\text{**}\\}$ and $w_{next} \\in \\{A,B,\\text{**}END\\text{**}\\}$. Fill in your answers in the table below.  (It might be easier to do this on paper first.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.666666666667\n",
      "0.333333333333\n",
      "0.0\n",
      "0.0\n",
      "0.666666666667\n",
      "0.333333333333\n",
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "def cond_prob(prv, nxt):\n",
    "    try:\n",
    "        bi = bi_counts_toy[prv][nxt] \n",
    "    except:\n",
    "        bi = 0\n",
    "    uni = uni_counts_toy[prv]\n",
    "    return bi/uni\n",
    "\n",
    "print cond_prob(\"A\",\"A\")\n",
    "print cond_prob(\"A\",\"B\")\n",
    "print cond_prob(\"A\",\"**END**\")\n",
    "print cond_prob(\"B\",\"A\")\n",
    "print cond_prob(\"B\",\"B\")\n",
    "print cond_prob(\"B\",\"**END**\")\n",
    "print cond_prob(\"**START**\",\"A\")\n",
    "print cond_prob(\"**START**\",\"B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER:**\n",
    "\n",
    "|        | P(wnext = A &#124;  w1) | P(wnext = B &#124; w1)  |  P(wnext = END &#124; w1)  | \n",
    "|--------|-------------------|--------|--------|\n",
    "| wprev = A | 0.66                  | 0.33      | 0      |\n",
    "| wprev = B | 0                | 0.66       | 0.33       |\n",
    "| wprev = START | 1.0              |   0     |        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part C: Draw samples from unigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Utility code**\n",
    "\n",
    "Please look at `hw2.py`, which contains `weighted_draw_from_dict(prob_dict)`.  You give it a dictionary where they keys are strings, and the values are their probabilities, and it returns a single random sample from that distribution.\n",
    "\n",
    "For example, run the following code a bunch of times.  It randomly returns `'a'` 75% of the time and `'b'` 25% of the time.\n",
    "\n",
    "(The import statement should work if hw2.py is in the same directory as this jupyter notebook file.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import hw2; reload(hw2)\n",
    "hw2.weighted_draw_from_dict({'a': 0.75, 'b': 0.25})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question C-1 (2 points):**\n",
    "\n",
    "If you drew from the above distribution 10,000 times, what is the expectation of the number of times `'a'` will occur?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "***ANSWER: 7500***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question C-2 (3 points):**\n",
    "\n",
    "Write a very small bit of test code to confirm `weighted_draw_from_dict` performs as advertised.  Draw from the above distribution 10,000 times and check to see the outcome of `'a'` occurs approximately the number of times it's expected to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7529\n"
     ]
    }
   ],
   "source": [
    "import hw2\n",
    "n = 0\n",
    "for i in range(10000):\n",
    "    key = hw2.weighted_draw_from_dict({'a': 0.75, 'b': 0.25})\n",
    "    if key == 'a':\n",
    "        n += 1\n",
    "\n",
    "print n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part D: Language model sampling\n",
    "\n",
    "In the following questions, we'll sample from a language model, based on ngram count tables, with a pseudocount of zero.\n",
    "\n",
    "First we'll write `draw_next_word_from_bigram_model` (which samples from $P(w)$) and then `draw_next_word_from_bigram_model` (which samples from $P(w_i | w_{i-1})$).\n",
    "Finally we'll write the `sample_sentence` function to sample a sentence from the bigram model.\n",
    "\n",
    "Throughout, make sure to test the code on the toy corpus: `uni_counts_toy` and `bi_counts_toy` from earlier in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question D-1: Draw from unigram distribution (10 points)**\n",
    "\n",
    "Please implement `draw_next_word_unigram_model` in hw2.py, and ensure the test cases below work correctly.  The starter code always returns a nonsense string, so the test cases should run out of the box, but give bad answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST CODE: run but do not change. Just take a sample.\n",
    "import hw2; reload(hw2)\n",
    "hw2.draw_next_word_unigram_model(uni_counts_toy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unigram counts: {'A': 3, 'B': 3, '**END**': 1, '**START**': 1}\n",
      "Random sample counts. Should have same proportions as original counts.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'**END**': 997, '**START**': 1031, 'A': 3007, 'B': 2965})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## TEST CODE: run but do not change. Take lots of samples.\n",
    "import hw2; reload(hw2)\n",
    "print \"unigram counts:\", uni_counts_toy\n",
    "from collections import Counter\n",
    "print \"Random sample counts. Should have same proportions as original counts.\"\n",
    "Counter([hw2.draw_next_word_unigram_model(uni_counts_toy) for i in range(8000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question D-2: Draw from bigram distribution (15 points)**\n",
    "\n",
    "Please implement `draw_next_word_bigram_model`.  It takes three parameters: the first two are the unigram and bigram count tables, which effectively define the model.  The third parameter is the previous context word.  Make sure both test cases below run with correct results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test code: draw once\n",
    "import hw2; reload(hw2)\n",
    "hw2.draw_next_word_bigram_model(uni_counts_toy,bi_counts_toy,\"A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREFIX A --> Counter({'A': 682, 'B': 318})\n",
      "PREFIX B --> Counter({'B': 653, '**END**': 347})\n",
      "PREFIX **START** --> Counter({'A': 1000})\n"
     ]
    }
   ],
   "source": [
    "## Test code: draw many times\n",
    "from collections import Counter\n",
    "for w in ['A','B','**START**']:\n",
    "    manydraws = [hw2.draw_next_word_bigram_model(uni_counts_toy,bi_counts_toy,w) \\\n",
    "                 for i in range(1000)]\n",
    "    sample_counts=Counter(manydraws)\n",
    "    print \"PREFIX %s --> %s\" % (w, sample_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question D-3: Implementing sentence sampling (30 points):**\n",
    "\n",
    "Next, you will write the function `sample_sentence` which generates a new sentence from a given model (and pseudocount value of 0). Here are some considerations:\n",
    "\n",
    "* You should reuse the `next_word_from_bigram_model` function.\n",
    "\n",
    "* You should generate a sentence that starts with \\*\\*START\\*\\* and ends with \\*\\*END\\*\\* token. Other sequences of words have zero probability under the model, so they should never be generated.  To start the function, you just set the first token to be \\*\\*START\\*\\* with probability one. You should keep randomly generating tokens, conditional on the previous word, until you generate the \\*\\*END\\*\\* token.\n",
    "\n",
    "* If your code has a bug and you enter an infinite loop and the \"Stop\" button in jupyter doesn't work, use Ctrl-C on the command line that launched the jupyter notebook.  You'll have to re-run all the cells to load back in the toy data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['**START**', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B', '**END**']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Test code -- draw one sample.  Run but do not change.  Run many times to be sure...\n",
    "import hw2; reload(hw2)\n",
    "hw2.sample_sentence(uni_counts_toy, bi_counts_toy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real Data!\n",
    "\n",
    "Now that everything works on a toy model, we'll run on real data based on the movie review dataset from HW1.  We have actually already peformed tokenization, normalization, and n-gram counting for you and are supplying you the unigram and bigram count tables.  Their structure is the same as the toy corpus ngram count dictionaries.  (If you're curious, we used [this script](http://people.cs.umass.edu/~brenocon/inlp2016/hw2/word_count_json.py) with NLTK to do the processing.)\n",
    "\n",
    "First, make sure the `unigram_count_IMDB.json` and `bigram_count_IMDB.json` files are in the current directory and load them with the following code.  Second, make sure you can sample from this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current working directory /Users/shamya/Documents/ML/585 NLP/HW/hw2\n",
      "loaded 22279 unigram types\n",
      "loaded 22278 bigram types\n"
     ]
    }
   ],
   "source": [
    "# Loading code\n",
    "import json, os\n",
    "print \"current working directory\", os.getcwd()\n",
    "uni_counts_IMDB = json.load(open('unigram_count_IMDB.json'))\n",
    "print \"loaded %s unigram types\" % len(uni_counts_IMDB)\n",
    "bi_counts_IMDB = json.load(open('bigram_count_IMDB.json'))\n",
    "print \"loaded %s bigram types\" % len(bi_counts_IMDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**START** not quite obviously borrowed all time at first time is far east ) and the visual aspect . **END**\n"
     ]
    }
   ],
   "source": [
    "# Take a sample\n",
    "import hw2; reload(hw2)\n",
    "print u' '.join(hw2.sample_sentence(uni_counts_IMDB, bi_counts_IMDB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part E: How Well do N-Gram Models Capture Grammar?\n",
    "\n",
    "**Question E-1 (20 points)**\n",
    "\n",
    "Sample ten sentences from the IMDB bigram model, then copy and paste them as text into the cell below.  For each, judge whether the sentence is grammatical in English.  How many sentences are grammatical out of 10?  If you had to formulate particular standards for how you define grammaticality, please explain.  (Notice we're talking about grammaticality, like whether the sentence is well-formed, as opposed to the sentence's meaning.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ANSWER:***\n",
    "\n",
    "I have defined grammaticality in a more modern sense where a sentence to be considered as gramatically correct and complete need not always have a subject-verb-object. Owing to be open to short sentences in tweets, status updates, text messages and reviews, I am open to ignore errors until it is structured to convey something (need not necessarily mean anything). Similarly, punctuations are ignored. In case of longer sentences, I have flagged the ones that isn't gramatically correct.\n",
    "\n",
    "1. ```**START** though in los angeles here. an eleven year since they could repopulate it 's chimney . **END**```\n",
    "**No**\n",
    "2. ```**START** the film seemed like the low-budget zombie movies shy away and i thought out the dvd because it is that holds out up until she accompanies . **END**```\n",
    "**No**\n",
    "3. ```**START** thus diluting the detraction of this makes a tv station and even buy a terrible , and had him literally opening flourish ; corbett . **END**```\n",
    "**No**\n",
    "4. ```**START** the secret police , director ) and 1918 . **END**```\n",
    "**Yes**\n",
    "5. ```**START** diana is also very closely to say that will believe that was solely through in my mind of all lost time it . **END**```\n",
    "**No**\n",
    "6. ```**START** the funniest scenes and -- remnants of co-stars as a little more original debut by a litter our household . **END**```\n",
    "**No**\n",
    "7. ```**START** dr eugene , watch . **END**```\n",
    "**Yes**\n",
    "8. ```**START** yellin respects . **END**```\n",
    "**Yes**\n",
    "9. ```**START** this show about it 's debt to firmly in the rest of earth. and the 70 's discovered by the main traits from the money , and the islanders point by emma from the less-engaging portions of is n't been a touch , but a happy . **END**```\n",
    "**No**\n",
    "10. ```**START** they train from his serious damage to providing you 're marketable . **END**```\n",
    "**No**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question E-2 (10 points)**\n",
    "\n",
    "Based on reading these samples, what are the strengths and weaknesses of n-gram language models?  What phenonmena can it model, and what does it get wrong?  When possible, please refer to specific examples in the sentences you just analyzed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ANSWER:***\n",
    "\n",
    "n-gram language models are good at modelling common occurences in a simple context. For example, in sample #2, a part of the phrase reads \"the film seemed like the low-budget zombie movies\". Even though it isn't meaningful, this has worked well to an extent. When there are strong correlations between the words occuring in a sequence, the sentence tends to be more sound. Also, with the increase in the length of the sentence, it severly suffers from loss of context (sample #9) making it more obscure. \n",
    "\n",
    "A clear strength of this approach is in its simplicity. And weakness is in its inefficiency with long range dependency. Including punctuations as tokens hasn't helped much except again for high probability pairs like it 's (sample #9) and you 're (sample #10). It was interesting to see the model pick the correct word pair to form a noun like los angeles (sample #1)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
